# SerpAPI Google Maps Reviews 分頁問題分析

## 📋 問題概述

在實施 Google Maps 評論收集系統時，我們遇到了 SerpAPI 分頁機制的關鍵問題：`next_page_token` 在某些情況下會失效，導致分頁收集中斷並重新開始，這可能造成評論數據的重複或遺漏。

## 🔍 問題現象

### 觀察到的行為
1. **第 1-3 頁正常收集**（第一次腳本執行）：
   - 第 1 頁：8 筆評論（SerpAPI 設計限制）
   - 第 2 頁：20 筆評論
   - 第 3 頁：20 筆評論

2. **第 4 頁重新開始**（第二次腳本執行）：
   - 收集時間間隔後，第 4 頁突然只返回 8 筆評論
   - 檢查 JSON 發現缺少 `num=20` 參數
   - 表明 `next_page_token` 失效，系統重新從第一頁開始

3. **後續頁面恢復正常**（繼續第二次腳本執行）：
   - 第 5-13 頁重新建立 token 鏈，各頁 20 筆評論

### 🚨 **重要發現：數據重複驗證**
**經過詳細檢查發現：第 4 頁的內容與第 1 頁完全相同！**

這證實了以下關鍵問題：
- **每次腳本重啟都重頭開始收集**
- **現有的斷點續傳機制根本無效**
- **只是跳過了檔案寫入，但 API 請求狀態完全重置**
- **實際上在重複收集相同的評論數據**

### 日誌證據
```
2025-09-22 22:19:40,833 - INFO - API 請求成功 - 頁數: 4, 評論數: 8, 執行時間: 0.55秒
2025-09-22 22:19:43,854 - INFO - API 請求成功 - 頁數: 5, 評論數: 20, 執行時間: 0.47秒
```

## 📚 官方文檔研究結果

### SerpAPI 分頁機制設計

根據官方文檔研究發現：

1. **Token 基礎分頁**：
   - 使用 `next_page_token` 進行順序分頁
   - 必須從前一頁獲取下一頁的 token
   - 不支援跳頁或隨機存取

2. **首頁特殊處理**：
   - 首頁預設返回 8 筆評論
   - 後續頁面可使用 `num` 參數控制數量（1-20）
   - `start` 參數已被 Google 廢棄

3. **官方推薦方式**：
   ```python
   # 使用 serpapi_pagination.next URL
   if result.get('serpapi_pagination', {}).get('next_page_token'):
       search.params_dict.update(dict(parse_qsl(urlsplit(result.get('serpapi_pagination', {}).get('next')).query)))
   ```

4. **已知限制**：
   - 分頁結果不包含 `place_info` 和 `topics`
   - Token 有時效性，長時間間隔可能失效
   - 無法保證跨會話的連續性

## 🎯 核心問題分析

### 根本原因：跨腳本執行的狀態矛盾
**SerpAPI Token 的會話級別特性**：
- `next_page_token` 僅存在於單次腳本執行的記憶體中
- 跨腳本執行時，token 狀態完全重置
- 無論檔案是否存在，API 都會重新從第一頁開始

**斷點續傳機制的根本缺陷**：
- 檔案存在檢查只能跳過**檔案寫入**操作
- 無法恢復**API 請求的分頁狀態**
- 導致後續請求實際上是重複的第一頁內容

### 當前架構限制
1. **基於檔案的狀態管理**：
   - 僅依賴頁碼進行斷點續傳
   - 無法追蹤評論的唯一性
   - 無法檢測重複或遺漏
   - **檔案跳過與 API 狀態分離**

2. **缺少連續性保證**：
   - 沒有評論去重機制
   - 沒有收集進度的可靠指標
   - 無法驗證數據完整性
   - **無法跨腳本執行保持 token 狀態**

### 架構矛盾加劇
**發現數據重複後，問題變得更加嚴重**：
- 不僅僅是"可能"重複，而是**確定會重複**
- API 額度的嚴重浪費
- 數據品質無法保證
- 現有解決方案治標不治本

## 💡 潛在解決方案

### 方案一：單次執行收集所有頁面（推薦）
**目標**：避免跨腳本執行，一次性收集完整數據
- ✅ **優點**：符合 SerpAPI 設計理念，避免重複問題
- ✅ **優點**：不需要複雜的狀態持久化
- ❌ **缺點**：對網路穩定性要求較高，單點故障風險

**具體措施**：
1. 設計單次執行收集目標頁數（如 50 頁）
2. 增強錯誤處理和重試機制
3. 加入進度監控和中間狀態保存
4. 實施網路中斷後的整體重啟策略

### 方案二：引入 SQLite（中等複雜度）
**目標**：本地資料庫 + 檔案系統混合
- ✅ **優點**：提供索引和去重能力，複雜度適中
- ❌ **缺點**：增加依賴，需要資料庫維護

**具體措施**：
1. SQLite 儲存評論唯一性索引
2. 基於評論指紋進行去重
3. 追蹤收集狀態和進度
4. 保留檔案系統作為主要儲存

### 方案三：完整資料庫方案（高複雜度）
**目標**：MySQL + 完整狀態管理
- ✅ **優點**：提供完整的資料一致性和擴展性
- ❌ **缺點**：顯著增加系統複雜度

**具體措施**：
1. MySQL 作為主要資料儲存
2. 實施事務性的收集狀態管理
3. 支援分散式收集和復原
4. 完整的評論生命週期管理

## 🤔 架構決策考量

### 複雜度 vs 可靠性權衡

| 方案 | 實施複雜度 | 維護成本 | 可靠性 | 擴展性 |
|------|------------|----------|--------|--------|
| 輕量級改進 | ⭐ | ⭐ | ⭐⭐ | ⭐ |
| SQLite 混合 | ⭐⭐ | ⭐⭐ | ⭐⭐⭐ | ⭐⭐ |
| MySQL 完整 | ⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐ |

### 專案需求分析
**當前規模**：
- 目標：收集永大夜市 7452 筆評論
- 預估：約 350-400 頁資料
- 頻率：一次性或低頻收集

**風險評估**：
- **資料遺漏風險**：中等（token 失效可能跳過評論）
- **重複資料風險**：中等（重啟後可能重複收集）
- **維護負擔**：當前較低

## 📝 建議與後續行動

### 即時行動（基於數據重複發現）
1. **停止當前的多次執行方式** - 已確認會產生重複數據
2. **設計單次執行策略** - 符合用戶傾向，避免跨腳本問題
3. **清理重複數據** - 移除第 4-13 頁的重複內容（與第 1-3 頁重複）

### 短期實施（1-2 週）
1. **實施方案一**：單次執行收集 50 頁
2. **增強穩定性**：改進錯誤處理和重試機制
3. **測試可靠性**：驗證長時間執行的穩定性

### 決策依據（更新後）
**強烈推薦方案一（單次執行）因為**：
- ✅ 用戶明確傾向此方案
- ✅ 避免了跨腳本執行的根本問題
- ✅ 符合 SerpAPI 的設計理念
- ✅ 不需要複雜的狀態持久化
- ✅ 徹底解決數據重複問題

**考慮其他方案如果**：
- 網路環境不穩定，長時間執行困難
- 需要支援大規模多地點收集
- 對容錯性有極高要求

### 當前狀態
**待決策項目**：
- [ ] 確認採用單次執行 50 頁的方案
- [ ] 設計長時間執行的穩定性改進
- [ ] 決定是否需要清理現有重複數據

---

**文檔建立日期**：2025-09-22
**最後更新**：2025-09-22（更新：記錄數據重複驗證結果）
**狀態**：待決策（傾向單次執行 50 頁方案）